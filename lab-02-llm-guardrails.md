# Lab 02: Enforcing LLM Safety with NeMo Guardrails

## Overview

In this lab, you'll extend the secure LLM-based command execution app from [Lab 01](https://github.com/olaekdahl/llm-labs/blob/main/lab-01-llm-secure-exec.md) by integrating **NVIDIA's NeMo Guardrails**.

You'll define structured *rails* that allow only specific commands to be generated by the LLM, ensuring even tighter control over its outputs ‚Äî no matter how creative the input gets.

---

## Learning Objectives

- Use NeMo Guardrails to restrict what an LLM can say or do
- Define action- and intent-level safety policies
- Route LLM responses through a safety layer before execution
- Reinforce OWASP recommendations on tool control and I/O filtering

---

## üß† Why Guardrails?

While Lab 01 enforced security through role-based checks **after** the LLM responded, this lab adds a **proactive layer** that filters and shapes the LLM output **before** it‚Äôs ever returned or executed.

This is crucial in agentic systems where LLMs may:

- Attempt unsafe commands
- Use unexpected phrasing or formatting
- Be influenced by malicious inputs

---

## üõ† Prerequisites

- Complete Lab 01
- Python 3.10+ (for running NeMo Guardrails)
- Node.js 20+
- Docker (optional)

---

## üß© System Architecture

```text
User ‚Üí Prompt ‚Üí NeMo Guardrails ‚Üí LLM ‚Üí Validated Command ‚Üí Execution
```

---

## ‚úÖ Step 1: Install NeMo Guardrails

In a terminal:

```bash
# use python or python3 depending on your environment
python3 -m venv .venv
source .venv/bin/activate
pip install nemoguardrails
```

Create a folder for your guardrails config:

```bash
mkdir rails
```

---

## ‚úÖ Step 2: Define Rail Policies

Create the file `rails/config.yml`:

```yaml
models:
  - type: main
    engine: openai
    model: gpt-3.5-turbo
```

Create `rails/prompt_rails.co`:

```co
define user express list_all_files
  "list all files"
  "show all files in directory"
  "list files"

define user express disk_usage
  "check disk usage"
  "show disk usage"

define user express memory_usage
  "check memory usage"
  "show memory stats"

define bot say ls
  "ls -la"

define bot say du
  "df -h"

define bot say free
  "free -m"

define flow list_files
  user express list_all_files
  bot say ls

define flow disk_usage
  user express disk_usage
  bot say du

define flow memory_usage
  user express memory_usage
  bot say free
```

This ensures only expected intent ‚Üí command flows are allowed.

---

## ‚úÖ Step 3: Add a Python Proxy

Create `guardrails_proxy.py`:

```python
from dotenv import load_dotenv
load_dotenv()

from nemoguardrails import LLMRails, RailsConfig
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()
config = RailsConfig.from_path("rails")
rails = LLMRails(config)

class Query(BaseModel):
    prompt: str

@app.post("/llm")
async def safe_llm(query: Query):
    result = await rails.generate_async(query.prompt)
    print(result)
    return { "command": result.strip() }
```

Run it with:

```bash
uvicorn guardrails_proxy:app --port 7000
```

---

## ‚úÖ Step 4: Update the Node.js Backend to Call Proxy

Update your `llm.ts` in the Node backend:

```ts
export async function getCommandFromLLM(query: string): Promise<string | null> {
  const res = await fetch("http://localhost:7000/llm", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ prompt: query }),
  });
  const data = await res.json();
  return data.command || null;
}
```

---

## ‚úÖ Step 5: Update the Node.js Backend to Call Proxy

Update your `server.ts` in the Node backend:

Change

```ts
const command = await getCommandFromLLM(query, token);
```

To

```ts
const command = await getCommandFromLLM(query);
```

Re-compile

```bash
tsc
```

---

## ‚úÖ Step 6: Test It

Make sure your Node server is running:

```bash
node dist/server.js
```

Try input like:

- "list all files" ‚Üí ‚úÖ "ls -la"
- "delete everything" ‚Üí ‚ùå blocked or empty

You now have multiple layers of control:

- NeMo: filters output before use
- Role policy: blocks execution by permission
- Audit log: tracks everything

---

## üîí What This Lab Demonstrates

- **Preemptive output filtering**
- **Secure orchestration** using LLMs
- **OWASP alignment** with:
  - Tool use restrictions
  - Input/output controls
  - Flow awareness

---

## üìù References

- [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails)
- [OWASP Securing Agentic Applications Guide](https://genai.owasp.org/resource/securing-agentic-applications-guide-1-0/)

---
